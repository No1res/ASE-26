基于你提供的文档和深刻的 Insights，这不仅仅是一个简单的规则调整，而是一次**从“代码裁剪”到“语义重建”的范式转移**。

以下是基于文档核心思想重新构建的 **“基于角色感知的自适应上下文构建系统” (Role-Aware Adaptive Context System, RAACS)** 的详细设计方案。

---

# 🚀 系统架构设计：Role-Aware Adaptive Context System (RAACS)

## 0. 核心设计哲学 (North Star Metric)

> 上下文的价值 $\neq$ 代码行数，而是 Mental Model（心智模型）的完整度。
> 
> 目标不是“塞入更多代码”，而是“以最低的 Token 成本，向 LLM 投射出最清晰的代码库语义拓扑”。

---

## 1. 模块一：语义拓扑映射 (The Semantic Map)

**目标**：解决“单纯 Hop 距离失效”的问题，利用图算法捕捉“隐性依赖”。

### 1.1 图构建与加权

不再使用无向的 Import 图，而是构建 **加权有向语义图 (Weighted Directed Semantic Graph, $G_{sem}$)**。

- **节点 ($V$)**：函数/类/模块（粒度视 AST 解析深度而定）。
    
- **边 ($E$)**：不仅包含 `import`，还包含数据流向。
    
- **边权 ($w_{ij}$)** 定义：
    
    $w_{ij} = \alpha \cdot I_{explicit} + \beta \cdot D_{data} + \gamma \cdot C_{call}$
    
    - $I_{explicit}$: 显式引用（Import/Include），基础权重。
        
    - $D_{data}$: 数据类型依赖（如参数类型、返回值类型），权重较高（代表 Schema 约束）。
        
    - $C_{call}$: 频繁调用（AST 统计调用次数），权重代表运行时耦合度。
        

### 1.2 个性化相关度计算 (Semantic Distance)

放弃简单的 BFS Hop 计数，采用 **以目标函数为起点的 Personalized PageRank (PPR)**。

- **定义**：设目标函数节点为 $v_{target}$，计算图中所有节点相对于 $v_{target}$ 的稳态概率分布 $\pi$。
    
- **公式**：
    
    $\pi = (1-d) \cdot \mathbf{r}_{start} + d \cdot \mathbf{M} \pi$
    
    其中 $\mathbf{r}_{start}$ 是仅在 $v_{target}$ 处为 1 的重启向量，$\mathbf{M}$ 是转移矩阵。
    
- **Insight**：
    
    - **High PPR Score** = 语义上强相关（即使物理路径很远，但如果是核心数据结构，会被反复游走击中）。
        
    - **Low PPR Score** = 偶然引用或噪声。
        

---

## 2. 模块二：角色感知与形态变换 (Role Identification & Morphing)

**目标**：解决“中心性高 $\neq$ 代码多”的问题，实现“角色适配的展示粒度”。

### 2.1 角色分类器 (The Classifier)

对候选节点进行角色打标（Labeling）。优先使用静态特征，模糊区使用 LLM。

|**角色 (Role)**|**静态特征判据 (Static Heuristics)**|**LLM 辅助判据 (Prompt Intent)**|
|---|---|---|
|**Schema / Model**|无逻辑分支，仅定义字段/属性，被多处引用作为类型。|"定义数据结构、协议或接口"|
|**Util / Helper**|入度极高，出度低，无副作用，纯函数特征明显。|"通用的工具函数，无业务上下文"|
|**Orchestrator**|包含复杂控制流，调用大量其他模块，位于调用链中上游。|"负责协调业务流程，核心逻辑"|
|**Config / Const**|全是大写变量，无函数定义，或仅包含 Key-Value。|"配置项或枚举值"|
|**Interface / Abstract**|方法体为空或仅有 `pass`/`throw`，被多处继承。|"抽象基类或接口定义"|

### 2.2 上下文形态变换器 (The Morpher)

根据角色 ($R$) 和 PPR 分数 ($S$)，决定最终生成的 Token 形态 ($T_{final}$)。

#### **规则 A: Schema / Interface (高压缩)**

- **策略**：**仅保留契约 (Contract-Only)。**
    
- **实现**：
    
    Python
    
    ```
    # 原始代码: class User(Base): ... (50 lines)
    # 变换后:
    class User:
        id: int
        name: str
        def is_active(self) -> bool: ...
        # (省略实现细节)
    ```
    
- **理由**：LLM 只需要知道“有什么字段”和“类型约束”。
    

#### **规则 B: Utility / Helper (黑盒化)**

- **策略**：**签名 + 用例 (Signature + Usage)。**
    
- **实现**：保留函数签名 + Docstring，并从仓库中找 1 个**最简调用示例 (One-shot example)** 附在后面。
    
- **理由**：工具函数的内部实现是干扰项，模型只需要知道 Input/Output 映射。
    

#### **规则 C: Orchestrator (骨架化)**

- **策略**：**保留骨架，折叠细节 (Skeletonization)。**
    
- **实现**：保留 `if/else/try/catch` 结构和函数调用，将具体计算块替换为注释 `... # calculating X`。
    
- **理由**：模型需要学习业务流程的“逻辑流”，而不是局部计算。
    

#### **规则 D: Config / Constant (值域化)**

- **策略**：**KV 列表。**
    
- **实现**：直接提取变量名和值。
    

---

## 3. 模块三：基于 MMR 的选择与预算控制 (Selection & Pruning)

**目标**：解决“冗余依赖”和“Token 预算”问题。

### 3.1 多目标打分 (Multi-Objective Scoring)

不仅考虑相关性，还要惩罚冗余。使用 Maximal Marginal Relevance (MMR) 思想。

对于候选集合 $C$ 和已选集合 $S$，下一个最佳节点 $n^*$ 为：

$$n^* = \underset{n \in C \setminus S}{\operatorname{argmax}} [\lambda \cdot \text{Sim}(n, \text{Target}) - (1-\lambda) \cdot \max_{s \in S} \text{Sim}(n, s)]$$

- **$\text{Sim}(n, \text{Target})$**：由 PPR 分数提供（相关性）。
    
- **$\max \text{Sim}(n, s)$**：惩罚与已选节点过于相似的候选者（避免选入两个功能重复的 Utils）。
    

### 3.2 成本分层的 LLM 决策 (Tiered Decision)

将 Token 成本集中在“刀刃”上。

1. **Tier 1 (White Zone)**: 静态规则确定的 Must-Have（如当前文件上下文、直接父类）。 -> **直接入选**。
    
2. **Tier 2 (Black Zone)**: PPR 分数极低或 Hop 过远。 -> **直接丢弃**。
    
3. **Tier 3 (Grey Zone)**: 静态特征模糊（如：名字很像但依赖路径远，或者是一个复杂的 Mixin）。
    
    - **Action**: 调用微型 LLM (e.g., GPT-3.5-Turbo / Claude Haiku)。
        
    - **Prompt**: "为了补全目标函数 X，片段 Y 是否必要？请打分 (0-5)。"
        
    - **Result**: 仅当得分 > 阈值时入选，并进行 LLM 压缩（Summary）。
        

---

## 4. 执行工作流总结 (Execution Workflow)

1. **解析与建图**：
    
    - 生成 AST。
        
    - 构建语义依赖图 $G_{sem}$（不仅仅是 Import，加入数据流权重）。
        
2. **相关性传播**：
    
    - 定位 Target Function 节点。
        
    - 运行 Personalized PageRank，得到每个节点的全局相关度 Score。
        
3. **角色识别 (Labeling)**：
    
    - 对 Top N 相关节点应用静态特征匹配，标记为 `Schema`, `Util`, `Orchestrator` 等。
        
    - 对特征不明显的节点标记为 `Uncertain`。
        
4. **形态生成 (Morphing)**：
    
    - `Schema` -> 转为 Type Definition。
        
    - `Util` -> 转为 Signature + 1-Shot Example。
        
    - `Orchestrator` -> 代码骨架化。
        
5. **MMR 贪心选择**：
    
    - 按照 Score - Redundancy 排序。
        
    - 填入 Prompt 直至达到 Token Window 上限。
        
6. **最终组装**：
    
    - 头部：全局 Config / 重要 Schema Summary。
        
    - 中部：相关模块的 Morphed Snippets。
        
    - 尾部：目标文件的完整 Context（Preceding/Following）。
        

---

## 5. Insight Check (反思与验证)

- **对比 Hop 距离**：本方案利用 PPR，能挖掘出深层但关键的 "Single Source of Truth"（如 5 层之外的全局配置），避免了 Hop 截断导致的上下文缺失。
    
- **对比原样代码**：通过 "Role-Based Morphing"，一个 100 行的 Schema 类被压缩为 10 行接口定义，节省了 90% Token，同时保留了 100% 的语义价值。
    
- **对比 LLM 全局打分**：引入 "Grey Zone" 策略，只在静态分析失效时使用 LLM，大幅降低了推理延迟和成本。
    